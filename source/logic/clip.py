import torch
from PIL import Image
import open_clip
from typing import Union, Tuple


class ImageClassifier:
    def __init__(self, model_name='ViT-SO400M-16-SigLIP2-512', pretrained='webli', text_labels=None):
        """
        åˆå§‹åŒ–åˆ†ç±»å™¨ï¼ŒåŠ è½½æ¨¡å‹ã€åˆ†è¯å™¨ã€é¢„å¤„ç†å’Œæ–‡æœ¬æ ‡ç­¾ã€‚

        Args:
            model_name (str): æ¨¡å‹åç§°ï¼Œå¦‚ 'ViT-SO400M-16-SigLIP2-512'
            pretrained (str): é¢„è®­ç»ƒæƒé‡ï¼Œå¦‚ 'webli'
            text_labels (list[str]): æ–‡æœ¬æ ‡ç­¾åˆ—è¡¨ï¼Œå¦‚ ["T-shirt", "dress", ...]
        """
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {self.device}")

        # åŠ è½½æ¨¡å‹å’Œé¢„å¤„ç†
        self.model, _, self.preprocess = open_clip.create_model_and_transforms(model_name, pretrained=pretrained)
        self.model.eval()
        self.model = self.model.to(self.device)

        # è·å–åˆ†è¯å™¨
        self.tokenizer = open_clip.get_tokenizer(model_name)

        if text_labels is None:
            raise ValueError("è¯·æä¾› text_labelsï¼Œå³ä½ è¦è¯†åˆ«çš„æ–‡æœ¬ç±»åˆ«åˆ—è¡¨ï¼Œä¾‹å¦‚ ['T-shirt', 'dress']ã€‚")
        self.text_labels = text_labels
        self.text_tokens = self.tokenizer(self.text_labels).to(self.device)  # tokenize å¹¶ç§»è‡³è®¾å¤‡

    def predict(self, image: Image.Image) -> Tuple[str, float]:
        """
        å¯¹ä¸€å¼  PIL.Image å›¾ç‰‡å¯¹è±¡è¿›è¡Œé¢„æµ‹ï¼Œè¿”å›æœ€å¯èƒ½çš„æ–‡æœ¬æ ‡ç­¾åŠç½®ä¿¡åº¦ï¼ˆç™¾åˆ†æ¯”ï¼‰ã€‚

        Args:
            image (PIL.Image.Image): è¾“å…¥çš„å›¾ç‰‡ï¼Œå¿…é¡»æ˜¯ PIL.Image å¯¹è±¡ï¼Œä¸”æœ€å¥½æ˜¯ RGB æ¨¡å¼

        Returns:
            Tuple[str, float]: (é¢„æµ‹çš„æ–‡æœ¬æ ‡ç­¾, ç½®ä¿¡åº¦ç™¾åˆ†æ¯”)ï¼Œä¾‹å¦‚ ("T-shirt", 95.67)
        """
        if not isinstance(image, Image.Image):
            raise TypeError(f"è¾“å…¥å¿…é¡»æ˜¯ PIL.Image å¯¹è±¡ï¼Œä½†ä¼ å…¥çš„æ˜¯ {type(image)}")

        # ç¡®ä¿å›¾ç‰‡æ˜¯ RGBï¼ˆå¦‚æœæ˜¯ RGBA æˆ– L ç­‰æ ¼å¼ï¼Œå¯èƒ½ä¼šæŠ¥é”™ï¼‰
        if image.mode != 'RGB':
            image = image.convert('RGB')

        try:
            # é¢„å¤„ç†å›¾ç‰‡
            image_tensor = self.preprocess(image).unsqueeze(0).to(self.device)  # [1, 3, H, W]

            # æ¨¡å‹æ¨ç†
            with torch.no_grad(), torch.autocast(device_type="cuda" if self.device == "cuda" else "cpu"):
                image_features = self.model.encode_image(image_tensor)
                text_features = self.model.encode_text(self.text_tokens)

                # å½’ä¸€åŒ– -> ä½™å¼¦ç›¸ä¼¼åº¦ -> softmax æ¦‚ç‡
                image_features /= image_features.norm(dim=-1, keepdim=True)
                text_features /= text_features.norm(dim=-1, keepdim=True)

                text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)

            probs = text_probs[0].cpu().numpy()
            predicted_idx = probs.argmax()
            predicted_label = self.text_labels[predicted_idx]
            confidence = float(probs[predicted_idx])*100  # å¦‚ 95.67

            return predicted_label, confidence

        except Exception as e:
            raise RuntimeError(f"å›¾ç‰‡æ¨ç†è¿‡ç¨‹ä¸­å‡ºé”™ï¼š{e}")


# ======================
# ğŸ” ä½¿ç”¨ç¤ºä¾‹ï¼ˆä¼ å…¥ PIL å›¾ç‰‡ï¼Œè€Œä¸æ˜¯è·¯å¾„ï¼‰
# ======================

if __name__ == "__main__":
    import time
    t = time.time()
    import cv2
    # å®šä¹‰ä½ æƒ³è¦è¯†åˆ«çš„ç±»åˆ«
    MY_TEXT_LABELS = [
        "T-shirt", "black clothing", "winter clothing", "summer clothing",
        "plush toy", "down jacket", "wallet", "sweater", "leggings",
        "underwear", "shoe", "dress"
    ]

    # åˆ›å»ºåˆ†ç±»å™¨
    classifier = ImageClassifier(
        model_name='ViT-SO400M-16-SigLIP2-512',
        pretrained='webli',
        text_labels=MY_TEXT_LABELS
    )

    image = cv2.imread(r"C:\Users\14676\Desktop\shoe\2025-09-03-14-46-50.png")

    # å‡å®šæ˜¯ OpenCV æ ¼å¼ï¼šnumpy æ•°ç»„ï¼ŒBGRï¼Œshape (H, W, 3)
    if image.ndim != 3 or image.shape[2] != 3:
        raise ValueError(f"OpenCV å›¾åƒåº”è¯¥æ˜¯ HWC æ ¼å¼ã€3é€šé“çš„ NumPy æ•°ç»„ï¼Œä½†å¾—åˆ°çš„æ˜¯ {image.shape}")
    # BGR è½¬ RGB
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    # è½¬ä¸º PIL.Image
    pil_image = Image.fromarray(image_rgb)

    # ç›´æ¥ä¼ å…¥ PIL.Image å¯¹è±¡è¿›è¡Œé¢„æµ‹
    try:
        label, confidence = classifier.predict(pil_image)
        print(f"ğŸ–¼ï¸ é¢„æµ‹ç»“æœï¼š'{label}'ï¼Œç½®ä¿¡åº¦ï¼š{confidence:.2f}%")
    except Exception as e:
        print(f"âŒ é¢„æµ‹å¤±è´¥ï¼š{e}")
    print(time.time()-t)